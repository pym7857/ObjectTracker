{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(202, 65, 168)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "video_path = 'data/kart.avi'\n",
    "\n",
    "cv2.namedWindow(\"LineTrackingWindow\")\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "Multitracker = cv2.MultiTracker_create()     # MultiTracker 객체 생성 \n",
    "\n",
    "# 첫번째 프레임 읽기\n",
    "ok, frame = cap.read()\n",
    "if not ok:\n",
    "    print('Failed to read video')\n",
    "    exit()    # 커널 종료 \n",
    "    \n",
    "bboxes = []\n",
    "n = 0\n",
    "while n<1:       # ROI 3번 설정 \n",
    "    bbox = cv2.selectROI('LineTrackingWindow', frame)   # BoundingBox 설정 \n",
    "    bboxes.append(bbox)\n",
    "    n += 1\n",
    "\n",
    "for bbox in bboxes:\n",
    "    Multitracker.add(cv2.TrackerMIL_create(), frame, bbox)  # Multitracker.add(알고리즘, 이미지, bbox)\n",
    "    \n",
    "'''\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "\"csrt\": cv2.TrackerCSRT_create,      # More accurate than KCF but slower. 낮은 프레임(fps25)에서 사용 (Best)\n",
    "\"kcf\": cv2.TrackerKCF_create,        # Fast and accurate. but 가림현상을 잘 처리하지 못함.\n",
    "\"boosting\": cv2.TrackerBoosting_create,  # 오래된 추적기로 성능이 떨어짐.\n",
    "\"mil\": cv2.TrackerMIL_create,            # boosting에 비해 정확도는 좋으나, 실패보고가 정상적으로 안됨.\n",
    "\"tld\": cv2.TrackerTLD_create,       # 가림현상에 잘 작동하나, Android버전에서 에러빈번하게 발생.\n",
    "\"medianflow\": cv2.TrackerMedianFlow_create,   # 실패보고가 잘 작동하나, 빠른 변화에 취약함 \n",
    "\"mosse\": cv2.TrackerMOSSE_create,     # Extremely fast but not as accurate as either KCF or CSRT\n",
    "\"goturn\": cv2.TrackerGOTURN_create    # 딥러닝 기반. 추가 모델 필요.\n",
    "}\n",
    "'''\n",
    "\n",
    "colors = []\n",
    "colors.append( (randint(0, 255),randint(0, 255), randint(0, 255)) )      # 랜덤컬러 3번설정 \n",
    "#colors.append( (randint(0, 255),randint(0, 255), randint(0, 255)) )\n",
    "#colors.append( (randint(0, 255),randint(0, 255), randint(0, 255)) )\n",
    "print(colors)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ok, frame = cap.read()        # 동영상을 1프레임씩 읽어온다. -> frame 변수에 넣는다.\n",
    "                                # 동영상 끝나면 ok = False\n",
    "    if not ok:\n",
    "        print ('no image to read')\n",
    "        break\n",
    "    \n",
    "    # ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    frame2 = cv2.resize(frame, (640, 360))           # 결과창을 (640, 360)으로  ReSize\n",
    "    dst = cv2.Canny(frame2, 500, 700, None, 3)       # Canny Edge Detection Algorithm \n",
    "                                                    # cv2.Canny (inputImage, minVal, maxVal)\n",
    "    \n",
    "    cdst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)     # GRAY -> BGR 인 image 생성\n",
    "    cdstP = np.copy(cdst)\n",
    "    \n",
    "    # Line 1 : Standard Hough Line Transform\n",
    "    lines = cv2.HoughLines(dst, 1, np.pi / 180, 170)  \n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(0, len(lines)):\n",
    "            rho = lines[i][0][0]\n",
    "            theta = lines[i][0][1]\n",
    "            a = math.cos(theta)\n",
    "            b = math.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))    # FirstPoint of line Segment\n",
    "            pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))    # SecondPoint of line Segment\n",
    "            cv2.line(cdst, pt1, pt2, (0, 0, 255), 3, cv2.LINE_AA)   # cv2.line(img, pt1, pt2, color, thickness, lineType)\n",
    "    \n",
    "    # Line 2 : Probabilistic Line Transform\n",
    "    linesP = cv2.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10)\n",
    "\n",
    "    if linesP is not None:\n",
    "        for i in range(0, len(linesP)):\n",
    "            l = linesP[i][0]\n",
    "            pt1 = (l[0], l[1])\n",
    "            pt2 = (l[2], l[3])\n",
    "            cv2.line(cdstP, pt1, pt2, (0, 0, 255), 3, cv2.LINE_AA)  \n",
    "    # ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    \n",
    "    ## Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    ok, boxes = Multitracker.update(frame)  # frame에서 설정한 boundingBox와 비슷한 물체의 위치를 \n",
    "                                            # 찾아(Update) 반환한다.\n",
    "    \n",
    "    ## Calculate Frames per second (FPS) \n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    "    \n",
    "    i = 0\n",
    "    for newbox in boxes:\n",
    "        # newbox의 왼쪽, 위쪽, 너비, 높이\n",
    "        left, top, w, h = [int(v) for v in newbox]\n",
    "        \n",
    "        # boxes의 색깔,두께 설정\n",
    "        cv2.rectangle(frame, pt1=(left, top), pt2=(left + w, top + h), color=colors[i], thickness=3)   # 이미지에 바운딩박스 그린다.\n",
    "        i += 1\n",
    "\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame, \"FPS : \" + str(int(fps)), (270,100), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255), 2)\n",
    "    \n",
    "    cv2.imshow('LineTrackingWindow', frame)\n",
    "    \n",
    "    cv2.imshow(\"Detected Lines (in red) - Standard Hough Line Transform\", cdst)\n",
    "    cv2.imshow(\"Detected Lines (in red) - Probabilistic Line Transform\", cdstP)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "```\n",
    "Canny Edge Detection : <https://m.blog.naver.com/samsjang/220507996391>\n",
    "Hough Transform (허프 변환) : <https://opencv-python.readthedocs.io/en/latest/doc/25.imageHoughLineTransform/imageHoughLineTransform.html>\n",
    "\n",
    "허프변환의 단점은 명확하다. 곡선에서는 사용이 불가능하며 차선이 아닌 직선도 차선으로 인식한다는 것이다.\n",
    "HSV를 이용한 필터링과 ROI로 영역을 나누면 꽤 쓸만해진다.\n",
    "이렇게 ROI로 영역을 선택하고 HSV 필터링을 이용해 차선만 남기고 제거하면 꽤 정확한 차선인식이 가능하다. \n",
    "그리고 대부분의 노이즈도 제거가 가능하고 곡선도 어느정도는 검출이 가능하다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.HoughLines?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
