{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "RIGHT\n",
      "LEFT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import sys\n",
    "from random import randint\n",
    "\n",
    "# ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ Wheel ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "class OptFlow:\n",
    "    def __init__(self, resize_width=800, resize_height=400, height_start=0.2, height_end=0.5):\n",
    "        self.width = resize_width\n",
    "        self.height = resize_height\n",
    "\n",
    "        self.height_start = int(self.height * height_start)\n",
    "        self.height_end = int(self.height * height_end)\n",
    "\n",
    "    def get_direction(self, frame1, frame2):\n",
    "        frame1 = cv2.resize(frame1, (self.width, self.height))\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame2 = cv2.resize(frame2, (self.width, self.height))\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(frame1[self.height_start:self.height_end],\n",
    "                                            frame2[self.height_start:self.height_end], None, 0.5, 3, 15, 1, 5, 1.2, 0)\n",
    "        flow_avg = np.median(flow, axis=(0, 1))\n",
    "\n",
    "        move_x = -1 * flow_avg[0]\n",
    "        move_y = -1 * flow_avg[1]\n",
    "\n",
    "        return move_x, move_y\n",
    "    \n",
    "flow = OptFlow()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cap = cv2.VideoCapture(\"data/testvideo.mp4\")      # 1920 1080\n",
    "cap = cv2.VideoCapture(\"data/kart.avi\")            # 1024 768\n",
    "#cap = cv2.VideoCapture(\"C:\\\\Users\\\\MiRcomputer\\\\Documents\\\\카트라이더\\\\비디오\\\\kart 2019-08-19 10-41-28-949.avi\")\n",
    "Multitracker = cv2.MultiTracker_create()     # MultiTracker 객체 생성\n",
    "#cv2.namedWindow(\"LineTrackingWindow\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ ROI ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "\n",
    "# 첫번째 프레임 읽기\n",
    "ok, src = cap.read()\n",
    "if not ok:\n",
    "    print('Failed to read video')\n",
    "    exit()    # 커널 종료 \n",
    "    \n",
    "bboxes = []\n",
    "n = 0\n",
    "while n<1:       # ROI 1번 설정    ->   3번설정: n < 3 \n",
    "    bbox = cv2.selectROI('Source', src)   # BoundingBox 설정 \n",
    "    bboxes.append(bbox)\n",
    "    n += 1\n",
    "\n",
    "for bbox in bboxes:\n",
    "    Multitracker.add(cv2.TrackerMIL_create(), src, bbox)  # Multitracker.add(알고리즘, 이미지, bbox)\n",
    "    \n",
    "'''\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "\"csrt\": cv2.TrackerCSRT_create,      # More accurate than KCF but slower. 낮은 프레임(fps25)에서 사용 (Best)\n",
    "\"kcf\": cv2.TrackerKCF_create,        # Fast and accurate. but 가림현상을 잘 처리하지 못함.\n",
    "\"boosting\": cv2.TrackerBoosting_create,  # 오래된 추적기로 성능이 떨어짐.\n",
    "\"mil\": cv2.TrackerMIL_create,            # boosting에 비해 정확도는 좋으나, 실패보고가 정상적으로 안됨.\n",
    "\"tld\": cv2.TrackerTLD_create,       # 가림현상에 잘 작동하나, Android버전에서 에러빈번하게 발생.\n",
    "\"medianflow\": cv2.TrackerMedianFlow_create,   # 실패보고가 잘 작동하나, 빠른 변화에 취약함 \n",
    "\"mosse\": cv2.TrackerMOSSE_create,     # Extremely fast but not as accurate as either KCF or CSRT\n",
    "\"goturn\": cv2.TrackerGOTURN_create    # 딥러닝 기반. 추가 모델 필요.\n",
    "}\n",
    "'''\n",
    "\n",
    "colors = []\n",
    "colors.append( (randint(0, 255),randint(0, 255), randint(0, 255)) )      # 랜덤컬러 3번설정 \n",
    "#colors.append( (randint(0, 255),randint(0, 255), randint(0, 255)) )\n",
    "#colors.append( (randint(0, 255),randint(0, 255), randint(0, 255)) )\n",
    "\n",
    "# ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ Wheel ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "ok, img1 = cap.read()\n",
    "ok, img2 = cap.read()\n",
    "\n",
    "\n",
    "while (True):\n",
    "    # ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ Wheel ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    x, y = flow.get_direction(img1, img2)\n",
    "    STEER = x*50\n",
    "\n",
    "    # print('STEER: {}'.format(STEER))        # 핸들 꺾는 각도 \n",
    "    if int(STEER) < 0 :\n",
    "        print('LEFT')\n",
    "\n",
    "    if int(STEER) > 0 :\n",
    "        print('RIGHT')\n",
    "\n",
    "    #cv2.imshow('result', img1)\n",
    "    wheel = cv2.imread('data/wheel_rion.png')\n",
    "    wheel = cv2.resize(wheel, dsize=(335, 335), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((335 / 2, 335 / 2), -int(STEER), 1)\n",
    "\n",
    "    wheel = cv2.warpAffine(wheel, M, (335, 335))\n",
    "\n",
    "    cv2.imshow('wheel', wheel)\n",
    "\n",
    "    img1 = img2\n",
    "    _, img2 = cap.read()\n",
    "    img2 = cv2.resize(img2, dsize=(640, 360), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ret, src = cap.read()    # frame 읽어오기\n",
    "    \n",
    "    if not ret:\n",
    "        print ('no image to read')\n",
    "        break\n",
    "        \n",
    "    # ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ ROI ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ    \n",
    "    ## Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    ok, boxes = Multitracker.update(src)  # frame에서 설정한 boundingBox와 비슷한 물체의 위치를 \n",
    "                                            # 찾아(Update) 반환한다.\n",
    "    \n",
    "    ## Calculate Frames per second (FPS) \n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    "    \n",
    "    i = 0\n",
    "    for newbox in boxes:\n",
    "        # newbox의 왼쪽, 위쪽, 너비, 높이\n",
    "        left, top, w, h = [int(v) for v in newbox]\n",
    "        \n",
    "        # boxes의 색깔,두께 설정\n",
    "        cv2.rectangle(src, pt1=(left, top), pt2=(left + w, top + h), color=colors[i], thickness=3)   # 이미지에 바운딩박스 그린다.\n",
    "        i += 1\n",
    "\n",
    "    # Display FPS on frame\n",
    "    # Green : (50,170,50)\n",
    "    cv2.putText(src, \"FPS : \" + str(int(fps)), (400,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 4)\n",
    "    \n",
    "    #cv2.imshow('LineTrackingWindow', src)\n",
    "    \n",
    "    # ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ Line ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "    src = cv2.resize(src, (1000, 650))              # 원본 Window\n",
    "    src_line_window = cv2.resize(src, (300, 200))     # Line Window\n",
    "\n",
    "    low_threshold = 800                     # 기본: 50 200 150\n",
    "    high_threshold = 920\n",
    "    dst = cv.Canny(src_line_window, low_threshold, high_threshold, None, \n",
    "                   apertureSize=3)   # 엣지 검출 알고리즘     \n",
    "    \n",
    "    '''\n",
    "    canny = cv2.Canny(src, 100, 255)\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, 3)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n",
    "    '''\n",
    "    \n",
    "    cdst = cv.cvtColor(dst, cv.COLOR_GRAY2BGR)\n",
    "    cdstP = np.copy(cdst)\n",
    "\n",
    "    rho = 1\n",
    "    theta = np.pi / 180\n",
    "    threshold = 58\n",
    "    \n",
    "    #min_line_length = 65\n",
    "    #max_line_gap = 5\n",
    "    \n",
    "    lines = cv.HoughLines(dst, rho, theta, threshold)   # 허프변환을 통한 라인검출 알고리즘    # Standard Hough Line Transform\n",
    "    #lines = cv.HoughLines(dst, 1, np.pi / 180, 150, None, min_line_length, max_line_gap)   # Probabilistic Line Transform\n",
    "    \n",
    "    if lines is not None:\n",
    "        for i in range(0, len(lines)):\n",
    "            rho = lines[i][0][0]\n",
    "            theta = lines[i][0][1]\n",
    "            a = math.cos(theta)\n",
    "            b = math.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))    # FirstPoint of line Segment\n",
    "            pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))    # SecondPoint of line Segment\n",
    "            cv2.line(cdst, pt1, pt2, (0, 0, 255), 3, cv2.LINE_AA)   # cv2.line(img, pt1, pt2, color, thickness, LINE_AA) \n",
    "    \n",
    "    '''\n",
    "    linesP = cv.HoughLinesP(dst, rho, theta, threshold, None, min_line_length, max_line_gap)\n",
    "\n",
    "    if linesP is not None:\n",
    "        for i in range(0, len(linesP)):\n",
    "            l = linesP[i][0]\n",
    "            pt1 = (l[0], l[1])\n",
    "            pt2 = (l[2], l[3])\n",
    "            cv.line(cdstP, pt1, pt2, (0, 0, 255), 3, cv.LINE_AA)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    cv.imshow(\"Source\", src)\n",
    "    cv.imshow(\"Detected Lines (in red) - Standard Hough Line Transform\", cdst)\n",
    "    #cv.imshow(\"Detected Lines (in red) - Probabilistic Line Transform\", cdstP)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "```\n",
    "<http://makeshare.org/bbs/board.php?bo_table=raspberrypi&wr_id=10>\n",
    "\n",
    "처음에 엣지 검출을 통해서 상당한 수의 자잘한 세그먼트들을 필터링한다면 \n",
    "이후에 이루어질 허프 변환 처리 속도가 빨라질 수 있다. \n",
    "\n",
    "그리고, lines = cv2.HoughLines(edges,1,np.pi/180,170)가 허프변환을 통해 라인을 검출하는 알고리즘이며, \n",
    "170이라는 숫자가 올라갈 수록 많은 교점이 있는 직선을 검출한다. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.HoughLines?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
